{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b6ac16",
   "metadata": {},
   "source": [
    "## Separating Transcription into Background Context and Actual Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ed07ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:03.089797Z",
     "iopub.status.busy": "2024-07-23T23:30:03.089566Z",
     "iopub.status.idle": "2024-07-23T23:30:03.711565Z",
     "shell.execute_reply": "2024-07-23T23:30:03.711277Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ayannair/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42dea128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:03.713482Z",
     "iopub.status.busy": "2024-07-23T23:30:03.713341Z",
     "iopub.status.idle": "2024-07-23T23:30:03.722266Z",
     "shell.execute_reply": "2024-07-23T23:30:03.722029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lyrics Sentences:\n",
      "There are some bops in the mix, but some of the themes addressed on this record are heavy. As she avoids agreements, business dealings, and traditional rules, looking to box her in, limit her capacity, the track has a chill vibe, thoughtful bars, and beautiful vocal traps. It's also pretty interesting that a lot of the group and choral vocals on this LP, as they are singing, the lyrics they deliver have often a religious or spiritual angle to them. But there are similar themes of control and autonomy on these songs Silhouette, where Sims voices once again distaste and unhappiness with being minimized in her own music, her creative process, her output, made to feel not human, but like a representation of a human or a human shape, a Silhouette. I feel much the same way about the instrumental arrangements and messaging on the song X, the themes and low-key melancholy vocal chops on the song Hard on Fire 2. Because Sims did spend a fair amount of time on that album, defining her own path, ethos, message, and independence. She paints her frustration with standout lines about paying for somebody else's ballman, and you've been tanning in the sun now I'm a throw shade. The bars, the word play, muah, muah, muah. But man, Sim's does an amazing job, a mind-blowing job in fact of just like kind of going through all of these problems and all the angles with mental health issues like in a very clear and lucid linear fashion, like not only is it's so fantastically written from a rap standpoint because the flows are there, the rhymes are there, but just in terms of a general point being made, the clarity of what she's trying to get across is so great. Meanwhile, the closing track control does have quite a bit of potential in its lyrics that explore trauma. So in terms of like cleanliness and detail and instrumental ambition, there is a bit of a wide gap between this cut and many other songs on the album. Why wouldn't you want to listen to tracks that either are left over from it or are still exploring at least some of the same vibes and themes, not just lyrically, but instrumentally and musically too. \n",
      "\n",
      "Production Sentences:\n",
      "There are some bops in the mix, but some of the themes addressed on this record are heavy. The only thing that doesn't hit about this track in my opinion is the beat which I thought ran a little thin and kind of stiff. We get creative synth work on this track, harder drums, also some choral passages that take up the entire second half of the track that are amazing and gorgeous. I feel much the same way about the instrumental arrangements and messaging on the song X, the themes and low-key melancholy vocal chops on the song Hard on Fire 2. The track doesn't feature one of my favorite beats on here outside of some of the orchestral hits that pop in here and there. But the Fluttering Cord loops and groove kind of provide a bit of an upbeat change of pace, which is also a vibe I get off of the song Gorilla, where the hilarious Whitten Braggadocia come through even harder. We have some elven-sized horn hits on this cut as well as some big, fat, heavy upright bass loops. The drums are super chunky and punchy as well. \n",
      "\n",
      "Features Sentences:\n",
      "The track doesn't feature one of my favorite beats on here outside of some of the orchestral hits that pop in here and there. But to get serious for a moment, this record also features the song Broken. \n",
      "\n",
      "Vocals Sentences:\n",
      "Coming through about a year after the release of her immense sometimes I might be introvert, which is an amazing profound rap album loaded with some of the most mind-blowing personal and moving songs in the genre that year. One that I know Sims can pretty confidently execute as she's done in the past, because again she can wrap her ass off, she can really drill down into a topic, and she can pull a cohesive batch of tracks together too. As she avoids agreements, business dealings, and traditional rules, looking to box her in, limit her capacity, the track has a chill vibe, thoughtful bars, and beautiful vocal traps. Plus the top-notch flows and word choices that we've come to expect from Sims up until this point. It's also pretty interesting that a lot of the group and choral vocals on this LP, as they are singing, the lyrics they deliver have often a religious or spiritual angle to them. But there are similar themes of control and autonomy on these songs Silhouette, where Sims voices once again distaste and unhappiness with being minimized in her own music, her creative process, her output, made to feel not human, but like a representation of a human or a human shape, a Silhouette. As she specifically focuses on what she sees as things that were trapping her in her career, three course meals and gifts, the rat race, being the only one who wasn't being paid, as well as contracts that were too long. But man, Sim's does an amazing job, a mind-blowing job in fact of just like kind of going through all of these problems and all the angles with mental health issues like in a very clear and lucid linear fashion, like not only is it's so fantastically written from a rap standpoint because the flows are there, the rhymes are there, but just in terms of a general point being made, the clarity of what she's trying to get across is so great. \n",
      "\n",
      "Concept Sentences:\n",
      "Coming through about a year after the release of her immense sometimes I might be introvert, which is an amazing profound rap album loaded with some of the most mind-blowing personal and moving songs in the genre that year. Because if you look at her catalog progression so far, she kind of alternates between these records that are very direct, more loosely connected collections of tracks, and then other albums that are just like kind of shooting for the stars conceptually. And yet also it feels like she's taken the experiences from that album, some of the instrumental concepts and ideas, the maturity that she gained on that LP, and is carrying it over into this new release here. The concept album is a tough beast to tame. There are some bops in the mix, but some of the themes addressed on this record are heavy. Plus the top-notch flows and word choices that we've come to expect from Sims up until this point. The only thing that doesn't hit about this track in my opinion is the beat which I thought ran a little thin and kind of stiff. But there are similar themes of control and autonomy on these songs Silhouette, where Sims voices once again distaste and unhappiness with being minimized in her own music, her creative process, her output, made to feel not human, but like a representation of a human or a human shape, a Silhouette. I feel much the same way about the instrumental arrangements and messaging on the song X, the themes and low-key melancholy vocal chops on the song Hard on Fire 2. And I guess if she still has things to say about it, it makes sense. She paints her frustration with standout lines about paying for somebody else's ballman, and you've been tanning in the sun now I'm a throw shade. The longest track on the LP by quite a bit, and when you get into the theme of the song, it's not hard to see why. But man, Sim's does an amazing job, a mind-blowing job in fact of just like kind of going through all of these problems and all the angles with mental health issues like in a very clear and lucid linear fashion, like not only is it's so fantastically written from a rap standpoint because the flows are there, the rhymes are there, but just in terms of a general point being made, the clarity of what she's trying to get across is so great. The brief sideways, I don't think, brings as much to the table as some of the heftier cuts here, while the auto-tune vocal leads and very mushy ill-defined chords on who even cares just are really not that appealing, not too much song structure to this track as well. But there is something about the presentation of the track that feels maybe a bit more demo-ish in comparison with everything else here. Why wouldn't you want to listen to tracks that either are left over from it or are still exploring at least some of the same vibes and themes, not just lyrically, but instrumentally and musically too. \n",
      "Review Segment:\n",
      "So yeah, unfortunately the record ends off much much much weaker than it starts. But still, I think no thank you is a pretty good project overall from Sims. Even if in some respects, it does feel like a sometimes I might be introvert epilogue. But that album is so great and so amazing. Why wouldn't you want to listen to tracks that either are left over from it or are still exploring at least some of the same vibes and themes, not just lyrically, but instrumentally and musically too. So I'm feeling a strong 7 to a light 8 on this one.\n"
     ]
    }
   ],
   "source": [
    "# Load the transcript from a file\n",
    "file_name = '/Users/ayannair/Documents/projects/fantanosize/backend/transcript.txt'\n",
    "with open(file_name, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# Define keywords for each topic\n",
    "keywords = {\n",
    "    'lyrics': ['lyrics', 'words', 'writing', 'verses', 'chorus', 'hook', 'poetry', 'lines', 'storytelling', 'themes', 'message', 'narrative', 'bars', 'line'],\n",
    "    'production': ['beat', 'melody', 'harmony', 'rhythm', 'production', 'sound', 'instrumentation', 'arrangement', 'synths', 'bass', 'drums', 'guitar', 'keys', 'mix', 'mastering', 'sonically'],\n",
    "    'features': ['feature', 'collaboration', 'guest', 'featuring', 'appearance', 'cameo', 'contribution'],\n",
    "    'vocals': ['vocals', 'singing', 'rap', 'voice', 'delivery', 'performance', 'flow'],\n",
    "    'concept': ['concept', 'theme', 'cohesion', 'consistency', 'flow', 'structure', 'production quality', 'about'],\n",
    "}\n",
    "\n",
    "topic_sentences = {topic: '' for topic in keywords}\n",
    "\n",
    "for sentence in sentences:\n",
    "    for topic, words in keywords.items():\n",
    "        if any(word in sentence.lower() for word in words):\n",
    "            topic_sentences[topic] += sentence + ' '\n",
    "\n",
    "\n",
    "# Print sentences about each topic\n",
    "for topic, sent in topic_sentences.items():\n",
    "    print(f\"\\n{topic.capitalize()} Sentences:\")\n",
    "    print(sent)\n",
    "\n",
    "# Find the last sentence with the word \"feeling\"\n",
    "target_index = None\n",
    "for i, sentence in enumerate(sentences):\n",
    "    if 'feeling a' in sentence.lower() or 'feeling' in sentence.lower() or 'strong' in sentence.lower() or 'light' in sentence.lower() or 'decent' in sentence.lower() or 'not good' in sentence.lower():\n",
    "        target_index = i\n",
    "\n",
    "# Check if we found a sentence with \"feeling\"\n",
    "if target_index is not None:\n",
    "    # Ensure we have enough sentences before\n",
    "    start_index = max(target_index - 5, 0)\n",
    "    end_index = target_index+1\n",
    "\n",
    "    # Extract the segment\n",
    "    review_seg = ' '.join(sentences[start_index:end_index])\n",
    "    print(\"Review Segment:\")\n",
    "    print(review_seg)\n",
    "else:\n",
    "    print(\"No sentence containing 'feeling a' was found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f16cd",
   "metadata": {},
   "source": [
    "## BERT Model Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4256a499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:03.723522Z",
     "iopub.status.busy": "2024-07-23T23:30:03.723430Z",
     "iopub.status.idle": "2024-07-23T23:30:04.616279Z",
     "shell.execute_reply": "2024-07-23T23:30:04.615891Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7272c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:04.618175Z",
     "iopub.status.busy": "2024-07-23T23:30:04.618063Z",
     "iopub.status.idle": "2024-07-23T23:30:06.257138Z",
     "shell.execute_reply": "2024-07-23T23:30:06.256804Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38308235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:06.259400Z",
     "iopub.status.busy": "2024-07-23T23:30:06.259179Z",
     "iopub.status.idle": "2024-07-23T23:30:06.261641Z",
     "shell.execute_reply": "2024-07-23T23:30:06.261286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define weights for each sentiment type\n",
    "weights = {\n",
    "    'neg': 0.1,\n",
    "    'neu': 0.2,\n",
    "    'pos': 0.7\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005041a",
   "metadata": {},
   "source": [
    "## Lyrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d307c7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:06.263446Z",
     "iopub.status.busy": "2024-07-23T23:30:06.263199Z",
     "iopub.status.idle": "2024-07-23T23:30:06.738788Z",
     "shell.execute_reply": "2024-07-23T23:30:06.738483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.035030607, 'roberta_neu': 0.3502545, 'roberta_pos': 0.61471486}\n",
      "71.97919493275029\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(topic_sentences[\"lyrics\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "lyrics_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(lyrics_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (lyrics_scores_dict['roberta_neg']*weights['neg'] + lyrics_scores_dict['roberta_neu']*weights['neu'] + lyrics_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "lyrics_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(lyrics_normalized_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895de0d1",
   "metadata": {},
   "source": [
    "## Production Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "214462bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:06.740594Z",
     "iopub.status.busy": "2024-07-23T23:30:06.740499Z",
     "iopub.status.idle": "2024-07-23T23:30:06.818310Z",
     "shell.execute_reply": "2024-07-23T23:30:06.817926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.039478056, 'roberta_neu': 0.32296997, 'roberta_pos': 0.63755196}\n",
      "73.5468820801803\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(topic_sentences[\"production\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "prod_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(prod_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (prod_scores_dict['roberta_neg']*weights['neg'] + prod_scores_dict['roberta_neu']*weights['neu'] + prod_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "prod_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(prod_normalized_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa27dd",
   "metadata": {},
   "source": [
    "## Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd76eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:06.820120Z",
     "iopub.status.busy": "2024-07-23T23:30:06.820017Z",
     "iopub.status.idle": "2024-07-23T23:30:06.853765Z",
     "shell.execute_reply": "2024-07-23T23:30:06.853341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.22720535, 'roberta_neu': 0.5859094, 'roberta_pos': 0.18688528}\n",
      "38.67458828857966\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(topic_sentences[\"features\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "feat_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(feat_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (feat_scores_dict['roberta_neg']*weights['neg'] + feat_scores_dict['roberta_neu']*weights['neu'] + feat_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "feat_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(feat_normalized_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5664b949",
   "metadata": {},
   "source": [
    "## Vocals Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b519a5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:06.855598Z",
     "iopub.status.busy": "2024-07-23T23:30:06.855490Z",
     "iopub.status.idle": "2024-07-23T23:30:06.997515Z",
     "shell.execute_reply": "2024-07-23T23:30:06.997148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.016838856, 'roberta_neu': 0.19196156, 'roberta_pos': 0.79119956}\n",
      "84.84512748462812\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(topic_sentences[\"vocals\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "vocals_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(vocals_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (vocals_scores_dict['roberta_neg']*weights['neg'] + vocals_scores_dict['roberta_neu']*weights['neu'] + vocals_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "vocals_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(vocals_normalized_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508dfb4",
   "metadata": {},
   "source": [
    "## Concept Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da46714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:06.999177Z",
     "iopub.status.busy": "2024-07-23T23:30:06.999080Z",
     "iopub.status.idle": "2024-07-23T23:30:07.179756Z",
     "shell.execute_reply": "2024-07-23T23:30:07.179284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.06255698, 'roberta_neu': 0.49183345, 'roberta_pos': 0.44560954}\n",
      "59.50700938701631\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(topic_sentences[\"concept\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "concept_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(concept_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (concept_scores_dict['roberta_neg']*weights['neg'] + concept_scores_dict['roberta_neu']*weights['neu'] + concept_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "concept_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(concept_normalized_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c5f79",
   "metadata": {},
   "source": [
    "## Overall Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5cf9c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:07.181874Z",
     "iopub.status.busy": "2024-07-23T23:30:07.181751Z",
     "iopub.status.idle": "2024-07-23T23:30:07.233652Z",
     "shell.execute_reply": "2024-07-23T23:30:07.233269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.042553872, 'roberta_neu': 0.14424068, 'roberta_pos': 0.8132055}\n",
      "86.04962272303443\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(review_seg, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "review_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(review_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (review_scores_dict['roberta_neg']*weights['neg'] + review_scores_dict['roberta_neu']*weights['neu'] + review_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "review_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(review_normalized_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c10e0568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T23:30:07.235929Z",
     "iopub.status.busy": "2024-07-23T23:30:07.235819Z",
     "iopub.status.idle": "2024-07-23T23:30:07.239163Z",
     "shell.execute_reply": "2024-07-23T23:30:07.238911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"lyrics_score\": 71.97919493275029,\n",
      "    \"production_score\": 73.5468820801803,\n",
      "    \"features_score\": 38.67458828857966,\n",
      "    \"vocals_score\": 84.84512748462812,\n",
      "    \"concept_score\": 59.50700938701631,\n",
      "    \"overall_score\": 86.04962272303443\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "scores_dict = {\n",
    "    'lyrics_score': lyrics_normalized_score,\n",
    "    'production_score': prod_normalized_score,\n",
    "    'features_score': feat_normalized_score,\n",
    "    'vocals_score': vocals_normalized_score,\n",
    "    'concept_score': concept_normalized_score,\n",
    "    'overall_score' : review_normalized_score\n",
    "}\n",
    "\n",
    "json_output = json.dumps(scores_dict, indent=4)\n",
    "\n",
    "print(json_output)\n",
    "\n",
    "results_fp = '/Users/ayannair/Documents/projects/fantanosize/backend/results.json'\n",
    "with open(results_fp, 'w') as json_file:\n",
    "    json.dump(scores_dict, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
