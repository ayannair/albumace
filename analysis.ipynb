{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b6ac16",
   "metadata": {},
   "source": [
    "## Separating Transcription into Background Context and Actual Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "67ed07ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ayannair/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "42dea128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lyrics Sentences:\n",
      "On this track, not only are the verses very fun, very entertaining, but Anderson brings his own chorus too. The chorus vocals on here are like a hot, breathy whisper in the ear, which is set against these very grand piano loops. Either the verses transition toward very underwhelming choruses or Anderson and his producers just kind of rely on almost one single loop to carry himself from one end of the track to the other. And in addition to that, there are a few songs in the second half here that I think are so smooth, they're so breezy, they're just kind of forgettable, regardless of the quality of the lyrics on these tracks, like parking lot or lifeway. \n",
      "\n",
      "Production Sentences:\n",
      "Dr. Dre's latest album slash soundtrack as well as even the new bus driver, mixed tape. And on this project, Pack sounds deeply influenced by the institutions of funk, jazz, hip hop, pop, R&B, all of which kind of blends together into a very smooth, neosol flavor, some of the time. But then, on cuts like put me through and celebrate, even though the production here is pretty fresh, it's pretty clean. And Anderson dips into rapping as well on this thing over a couple of beats that are very jazzy fractured, produced by ninth wonder, specifically on the song without you. The highlights on this thing continue like on the song, Come Down, which has a five star bassline from Wink, Wink, Wink, Wink, Wink, Wink, Wink, Wink, Wink, Wink, Wink, Wink, Wink. There's a mean drum beat behind this thing too over this track. It's really a hot cut on the album for me, even though the song and the beat, I think do get a little redundant over the runtime of the track. I just think there are moments on the record that could have done with more live instrumentation like the very tight sequenced synthetic production all over this thing. There are a few moments here where I think Anderson drowns in some trendy sounds, unfortunately. It sounds like Anderson is so close to something great and something stellar on this album. \n",
      "\n",
      "Features Sentences:\n",
      "And you cannot say that Anderson not tried to do it big on this thing, given that he's handed over an hour of material, 16 tracks on this thing with features from Rhapsody, the game, schoolboy Q, as well as BJ, the Chicago Kid, Talibwe, and more. But I sort of knew that was going to be the case going into it, given how many great vocal features Anderson has laid down in the past. The games feature here is pretty good. \n",
      "\n",
      "Vocals Sentences:\n",
      "And he's been making quite a splash lately, lending his very passionate, raspy, dynamic vocals to projects both big and small. However, many of these new faces aren't paired with very strong voices, unfortunately. But the vocal performance is here, actually really good. The singing on this thing, it's full of emotion. And Anderson dips into rapping as well on this thing over a couple of beats that are very jazzy fractured, produced by ninth wonder, specifically on the song without you. The chorus vocals on here are like a hot, breathy whisper in the ear, which is set against these very grand piano loops. \n",
      "\n",
      "Concept Sentences:\n",
      "And there are actually quite a few cuts on here, which aren't really love themed or anything like that. \n",
      "Review Segment:\n",
      "I just think on the next release cut the fat and turn up the heat because I think some of the hotter heavier more in a way aggressive and just swagger-laced tracks would have picked up the intensity on this thing, would have picked up the momentum. I think we would have made it a little more entertaining. But still regardless, I do recommend that you check this thing out. It's a great funky hip hop fused soul record.\n"
     ]
    }
   ],
   "source": [
    "# Load the transcript from a file\n",
    "file_name = '/Users/ayannair/Documents/projects/fantanosize/backend/transcript.txt'\n",
    "with open(file_name, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# Define keywords for each topic\n",
    "keywords = {\n",
    "    'lyrics': ['lyrics', 'words', 'writing', 'verses', 'chorus', 'hook', 'poetry', 'lines', 'storytelling', 'themes', 'message', 'narrative', 'bars', 'line'],\n",
    "    'production': ['beat', 'melody', 'harmony', 'rhythm', 'production', 'sound', 'instrumentation', 'arrangement', 'synths', 'bass', 'drums', 'guitar', 'keys', 'mix', 'mastering', 'sonically'],\n",
    "    'features': ['feature', 'collaboration', 'guest', 'featuring', 'appearance', 'cameo', 'contribution'],\n",
    "    'vocals': ['vocals', 'singing', 'rap', 'voice', 'delivery', 'performance', 'flow'],\n",
    "    'concept': ['concept', 'theme', 'cohesion', 'consistency', 'flow', 'structure', 'production quality', 'about'],\n",
    "}\n",
    "\n",
    "topic_sentences = {topic: '' for topic in keywords}\n",
    "\n",
    "for sentence in sentences:\n",
    "    for topic, words in keywords.items():\n",
    "        if any(word in sentence.lower() for word in words):\n",
    "            topic_sentences[topic] += sentence + ' '\n",
    "\n",
    "\n",
    "# Print sentences about each topic\n",
    "for topic, sent in topic_sentences.items():\n",
    "    print(f\"\\n{topic.capitalize()} Sentences:\")\n",
    "    print(sent)\n",
    "\n",
    "# Find the last sentence with the word \"feeling\"\n",
    "target_index = None\n",
    "for i, sentence in enumerate(sentences):\n",
    "    if 'feeling a' in sentence.lower() or 'feeling' in sentence.lower() or 'strong' in sentence.lower() or 'light' in sentence.lower() or 'decent' in sentence.lower() or 'not good' in sentence.lower():\n",
    "        target_index = i\n",
    "\n",
    "# Check if we found a sentence with \"feeling\"\n",
    "if target_index is not None:\n",
    "    # Ensure we have enough sentences before\n",
    "    start_index = max(target_index - 5, 0)\n",
    "    end_index = target_index+1\n",
    "\n",
    "    # Extract the segment\n",
    "    review_seg = ' '.join(sentences[start_index:end_index])\n",
    "    print(\"Review Segment:\")\n",
    "    print(review_seg)\n",
    "else:\n",
    "    print(\"No sentence containing 'feeling a' was found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f16cd",
   "metadata": {},
   "source": [
    "## BERT Model Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4256a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8a7272c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "38308235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for each sentiment type\n",
    "weights = {\n",
    "    'neg': 0.1,\n",
    "    'neu': 0.2,\n",
    "    'pos': 0.7\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005041a",
   "metadata": {},
   "source": [
    "## Lyrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d307c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.089506656, 'roberta_neu': 0.34845048, 'roberta_pos': 0.5620429}\n",
      "67.43868376527514\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(topic_sentences[\"lyrics\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "lyrics_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(lyrics_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (lyrics_scores_dict['roberta_neg']*weights['neg'] + lyrics_scores_dict['roberta_neu']*weights['neu'] + lyrics_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "lyrics_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(lyrics_normalized_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895de0d1",
   "metadata": {},
   "source": [
    "## Production Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "214462bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.11050688, 'roberta_neu': 0.6085486, 'roberta_pos': 0.28094453}\n",
      "47.0602246267455\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(topic_sentences[\"production\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "prod_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(prod_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (prod_scores_dict['roberta_neg']*weights['neg'] + prod_scores_dict['roberta_neu']*weights['neu'] + prod_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "prod_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(prod_normalized_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa27dd",
   "metadata": {},
   "source": [
    "## Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bcd76eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.0050596017, 'roberta_neu': 0.08842029, 'roberta_pos': 0.9065201}\n",
      "93.2505867577025\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(topic_sentences[\"features\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "feat_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(feat_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (feat_scores_dict['roberta_neg']*weights['neg'] + feat_scores_dict['roberta_neu']*weights['neu'] + feat_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "feat_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(feat_normalized_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5664b949",
   "metadata": {},
   "source": [
    "## Vocals Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9b519a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.008635747, 'roberta_neu': 0.12466246, 'roberta_pos': 0.8667018}\n",
      "90.3553305326828\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(topic_sentences[\"vocals\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "vocals_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(vocals_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (vocals_scores_dict['roberta_neg']*weights['neg'] + vocals_scores_dict['roberta_neu']*weights['neu'] + vocals_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "vocals_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(vocals_normalized_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508dfb4",
   "metadata": {},
   "source": [
    "## Concept Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1da46714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.31256625, 'roberta_neu': 0.60188913, 'roberta_pos': 0.08554464}\n",
      "30.21652836884771\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(topic_sentences[\"concept\"], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "concept_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(concept_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (concept_scores_dict['roberta_neg']*weights['neg'] + concept_scores_dict['roberta_neu']*weights['neu'] + concept_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "concept_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(concept_normalized_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c5f79",
   "metadata": {},
   "source": [
    "## Overall Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d5cf9c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.01884759, 'roberta_neu': 0.2877919, 'roberta_pos': 0.6933605}\n",
      "77.82792797578233\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text\n",
    "encoded_text = tokenizer(review_seg, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Ensure no issues with input dimensions\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    scores = output.logits[0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "# Extract numerical values\n",
    "review_scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "\n",
    "print(review_scores_dict)\n",
    "\n",
    "# Compute the combined sentiment score\n",
    "combined_score = (review_scores_dict['roberta_neg']*weights['neg'] + review_scores_dict['roberta_neu']*weights['neu'] + review_scores_dict['roberta_pos']*weights['pos'])\n",
    "\n",
    "# Normalize the score\n",
    "review_normalized_score = combined_score/0.7*100\n",
    "\n",
    "print(review_normalized_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c10e0568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"lyrics_score\": 67.43868376527514,\n",
      "    \"production_score\": 47.0602246267455,\n",
      "    \"features_score\": 93.2505867577025,\n",
      "    \"vocals_score\": 90.3553305326828,\n",
      "    \"concept_score\": 30.21652836884771,\n",
      "    \"overall_score\": 77.82792797578233\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "scores_dict = {\n",
    "    'lyrics_score': lyrics_normalized_score,\n",
    "    'production_score': prod_normalized_score,\n",
    "    'features_score': feat_normalized_score,\n",
    "    'vocals_score': vocals_normalized_score,\n",
    "    'concept_score': concept_normalized_score,\n",
    "    'overall_score' : review_normalized_score\n",
    "}\n",
    "\n",
    "json_output = json.dumps(scores_dict, indent=4)\n",
    "\n",
    "print(json_output)\n",
    "\n",
    "results_fp = '/Users/ayannair/Documents/projects/fantanosize/backend/results.json'\n",
    "with open(results_fp, 'w') as json_file:\n",
    "    json.dump(scores_dict, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
